{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135e0c0e-dacd-49d7-8f6b-610e7725e142",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b5b403-3ac6-467b-84ec-b205cc2deb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    GenerationConfig,\n",
    "    LogitsProcessor\n",
    ")\n",
    "from peft.tuners.lora import LoraLayer\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ad8c23-f192-4fd4-af5e-b4315b5149e8",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f04a090-a376-41c0-bae0-78d2859b129f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/mnt/shared/tibor/Llama-2-13b-chat-hf\"\n",
    "NOT_ANSWERABLE_INCLUDED=False\n",
    "MAX_NEW_TOKENS = 128\n",
    "OUTPUT_FILE = \"test_llama_13b_4bit_finetuned_all_answerable\"\n",
    "USE_ADAPTER = True\n",
    "ADAPTER = \"./results/results_w_eos_13b/checkpoint-1500\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cff34-015b-46ad-8b5c-9a150706e084",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ba82a6-8418-4bd3-ba8d-d2942bf3377a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EosTokenRewardLogitsProcessor(LogitsProcessor):\n",
    "  def __init__(self,  eos_token_id: int, max_length: int):\n",
    "    \n",
    "        if not isinstance(eos_token_id, int) or eos_token_id < 0:\n",
    "            raise ValueError(f\"`eos_token_id` has to be a positive integer, but is {eos_token_id}\")\n",
    "\n",
    "        if not isinstance(max_length, int) or max_length < 1:\n",
    "          raise ValueError(f\"`max_length` has to be a integer bigger than 1, but is {max_length}\")\n",
    "\n",
    "        self.eos_token_id = eos_token_id\n",
    "        self.max_length=max_length\n",
    "\n",
    "  def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor) -> torch.FloatTensor:\n",
    "    cur_len = input_ids.shape[-1]\n",
    "    # start to increese the reward of the  eos_tokekn from 80% max length  progressively on length\n",
    "    for cur_len in (max(0,int(self.max_length*0.8)), self.max_length ):\n",
    "      ratio = cur_len/self.max_length\n",
    "      num_tokens = scores.shape[1] # size of vocab\n",
    "      scores[:, [i for i in range(num_tokens) if i != self.eos_token_id]] =\\\n",
    "      scores[:, [i for i in range(num_tokens) if i != self.eos_token_id]]*ratio*10*torch.exp(-torch.sign(scores[:, [i for i in range(num_tokens) if i != self.eos_token_id]]))\n",
    "      scores[:, self.eos_token_id] = 1e2*ratio\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889c8c28-c787-4e69-baae-6df8f979148a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "#Create a new token and add it to the tokenizer\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"})\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f62ff60-6ad5-48d0-be5f-dca6efe1c235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db452915f0054fdbaea90d4849d32538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          model_path, quantization_config=bnb_config, device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40364437-7956-4a10-bca6-2e54b60aed28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32016, 5120)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resize the embeddings\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16) # https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de045f30-62a9-4881-a45b-23e54780075d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False # Gradient checkpointing is used by default but not compatible with caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e258673-4ff4-439e-b3d7-eade79520c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ./results/results_w_eos_13b/checkpoint-1500 as adapter\n"
     ]
    }
   ],
   "source": [
    "if USE_ADAPTER:\n",
    "    print(\"Using \" + ADAPTER + \" as adapter\")\n",
    "    model = PeftModel.from_pretrained(model, ADAPTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad47a38-df75-4d3d-a0c5-d23578b336cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "impossible_answer = \"Nincs elegendő adat a kérdés megválaszolásához.\"\n",
    "prompt_prefix = None\n",
    "\n",
    "if NOT_ANSWERABLE_INCLUDED:\n",
    "    prompt_prefix = (\"Válaszold meg az alábbi kérdést a forrás alapján! \"\n",
    "                     \"Ha a forrás alapján nem megválaszolható a kérdés, mondd hogy: \"\n",
    "                     f\"{impossible_answer}\")\n",
    "else:\n",
    "    prompt_prefix = (\"Válaszold meg az alábbi kérdést a forrás alapján!\")\n",
    "\n",
    "\n",
    "def generate(context: str, question: str, use_source: bool = True):\n",
    "    prompt = None\n",
    "    if use_source:\n",
    "        prompt = (prompt_prefix\n",
    "                  + \"\\n### Forrás:\\n\" + str(context)\n",
    "                  + \"\\n### Kérdés:\\n\" + str(question)\n",
    "                  + \"\\n### Válasz:\\n\")\n",
    "    else:\n",
    "        prompt = (\"Válaszold meg az alábbi kérdést\"\n",
    "                 + \"\\n### Kérdés:\\n\" + str(question)\n",
    "                 + \"\\n### Válasz:\\n\")\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    # print(f\"{len(input_ids[0])=}\")\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        do_sample=True,\n",
    "        # top_p=1.0,\n",
    "        # top_k=50,\n",
    "        # num_beams=1,\n",
    "        temperature=0.2,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=MAX_NEW_TOKENS)\n",
    "\n",
    "    generation_output = model.generate(\n",
    "            # logits_processor=[EosTokenRewardLogitsProcessor(eos_token_id=tokenizer.eos_token_id, max_length = 64)],\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config)\n",
    "\n",
    "    for seq in generation_output.sequences:\n",
    "        output = tokenizer.decode(seq)\n",
    "        return output.split(\"### Válasz:\\n\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f9f647-eeaa-4ded-b731-0e397b6b3fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "483"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/test.csv\", sep=';')\n",
    "test_df_len = len(test_df)\n",
    "test_count = int(test_df_len)\n",
    "# test_count = 10\n",
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04b02aed-a90e-4441-80c0-4517882cc6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inferences: 100%|███████████████████████████████████████████████████████████| 483/483 [2:25:47<00:00, 18.11s/it]\n"
     ]
    }
   ],
   "source": [
    "rouge = ROUGEScore()\n",
    "r_scores_sum=0\n",
    "results = {\"reference\": [],\n",
    "           \"question\": [],\n",
    "           \"correct_answer\": [],\n",
    "           \"answer_w_ref\": [],\n",
    "           \"answer_no_ref\": [],\n",
    "           \"rouge1_fmeasure\": []}\n",
    "\n",
    "with tqdm(total=test_count, desc=\"Running inferences\") as pbar:\n",
    "    for index, row in test_df.iloc[:test_count].iterrows():\n",
    "\n",
    "        answer_w_ref = generate(context=row['context'], question=row['question'])\n",
    "        answer_no_ref = generate(context=row['context'], question=row['question'], use_source=False)\n",
    "\n",
    "        r_score = float(rouge(answer_w_ref, row['answer'])['rouge1_fmeasure'])\n",
    "        r_scores_sum = r_scores_sum + r_score\n",
    "\n",
    "        results[\"reference\"].append(row[\"context\"])\n",
    "        results[\"question\"].append(row[\"question\"])\n",
    "        results[\"correct_answer\"].append(row[\"answer\"])\n",
    "        results[\"answer_w_ref\"].append(answer_w_ref)\n",
    "        results[\"answer_no_ref\"].append(answer_no_ref)\n",
    "        results[\"rouge1_fmeasure\"].append(r_score)\n",
    "\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ae35a9-54a2-49fb-ad8d-4705ecb8aaed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average r_score: 0.7129637124190419\n"
     ]
    }
   ],
   "source": [
    "print(\"Average r_score: \"+str(r_scores_sum/test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00baa736-67fb-4cb8-bb17-5ab8802defda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>answer_w_ref</th>\n",
       "      <th>answer_no_ref</th>\n",
       "      <th>rouge1_fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A női körülmetélés (vagyis a női nemi szervek ...</td>\n",
       "      <td>Mit jelent a női körülmetélés?</td>\n",
       "      <td>A női körülmetélés (vagyis a női nemi szervek ...</td>\n",
       "      <td>A női körülmetélés (vagyis a női nemi szervek ...</td>\n",
       "      <td>A női körülmetélés (vagy női genitalia megcson...</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budapest villamosvonal-hálózata a magyar fővár...</td>\n",
       "      <td>Mikor indult meg a lóvasút Budán?</td>\n",
       "      <td>Budán csak 1868. május 18-án avatták fel az el...</td>\n",
       "      <td>Budán csak 1868. május 18-án avatták fel az el...</td>\n",
       "      <td>A lóvasút Budán 1864. április 27-én indult meg...</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apja testvérének fiai, azaz István unokatestvé...</td>\n",
       "      <td>Volt testvére Orseolo Péternek?</td>\n",
       "      <td>Választása végül Ilona nevű lánytestvérének fi...</td>\n",
       "      <td>Választása végül Ilona nevű lánytestvérének fi...</td>\n",
       "      <td>Orseolo Péternek volt egy testvére, Orseolo Ot...</td>\n",
       "      <td>0.992126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A globális felmelegedés következtében a gleccs...</td>\n",
       "      <td>A gleccserek édes vagy sós vizet tartalmaznak?</td>\n",
       "      <td>A globális felmelegedés következtében a gleccs...</td>\n",
       "      <td>A globális felmelegedés következtében a gleccs...</td>\n",
       "      <td>A gleccserek édes víztartalmazza, amelyet a hó...</td>\n",
       "      <td>0.979592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Az átlagos egyiptomi lakóépületek a falvakban ...</td>\n",
       "      <td>Min aludtak az ókori egyiptomiak?</td>\n",
       "      <td>Szalmazsákon aludtak, párna helyett kőből vagy...</td>\n",
       "      <td>Szalmazsákon aludtak, párna helyett kőből vagy...</td>\n",
       "      <td>A 2. és 3. életkorban a gyermekek a gyakorlatb...</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  A női körülmetélés (vagyis a női nemi szervek ...   \n",
       "1  Budapest villamosvonal-hálózata a magyar fővár...   \n",
       "2  Apja testvérének fiai, azaz István unokatestvé...   \n",
       "3  A globális felmelegedés következtében a gleccs...   \n",
       "4  Az átlagos egyiptomi lakóépületek a falvakban ...   \n",
       "\n",
       "                                         question  \\\n",
       "0                  Mit jelent a női körülmetélés?   \n",
       "1               Mikor indult meg a lóvasút Budán?   \n",
       "2                 Volt testvére Orseolo Péternek?   \n",
       "3  A gleccserek édes vagy sós vizet tartalmaznak?   \n",
       "4               Min aludtak az ókori egyiptomiak?   \n",
       "\n",
       "                                      correct_answer  \\\n",
       "0  A női körülmetélés (vagyis a női nemi szervek ...   \n",
       "1  Budán csak 1868. május 18-án avatták fel az el...   \n",
       "2  Választása végül Ilona nevű lánytestvérének fi...   \n",
       "3  A globális felmelegedés következtében a gleccs...   \n",
       "4  Szalmazsákon aludtak, párna helyett kőből vagy...   \n",
       "\n",
       "                                        answer_w_ref  \\\n",
       "0  A női körülmetélés (vagyis a női nemi szervek ...   \n",
       "1  Budán csak 1868. május 18-án avatták fel az el...   \n",
       "2  Választása végül Ilona nevű lánytestvérének fi...   \n",
       "3  A globális felmelegedés következtében a gleccs...   \n",
       "4  Szalmazsákon aludtak, párna helyett kőből vagy...   \n",
       "\n",
       "                                       answer_no_ref  rouge1_fmeasure  \n",
       "0  A női körülmetélés (vagy női genitalia megcson...         0.756757  \n",
       "1  A lóvasút Budán 1864. április 27-én indult meg...         0.983051  \n",
       "2  Orseolo Péternek volt egy testvére, Orseolo Ot...         0.992126  \n",
       "3  A gleccserek édes víztartalmazza, amelyet a hó...         0.979592  \n",
       "4  A 2. és 3. életkorban a gyermekek a gyakorlatb...         0.980392  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df=pd.DataFrame(results)\n",
    "results_df.to_csv(OUTPUT_FILE+\".csv\", sep=';')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec39cc9-1b51-4ce8-84a0-67fe6779863a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f892757e-ded7-4fbf-a0d8-1ccc5ca28206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
