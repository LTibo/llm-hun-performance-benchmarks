


import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import numpy as np





INCLUDE_IMPOSSIBLE = True
USE_MOD_ANSWER = False
OUTPUT_NAME = "w_noansw"





pd.set_option('display.max_columns', None)
hun_data = pd.read_csv("data/dev_long_impossible_yes_no_arithmetic.csv", sep=';')


hun_data = hun_data.drop(hun_data.columns[0], axis=1) # drop nameless column
hun_data.head()


hun_data.dtypes


impossible_answer = "Nincs elegendő adat a kérdés megválaszolásához."

if INCLUDE_IMPOSSIBLE:
    prompt_prefix = ("Válaszold meg az alábbi kérdést a forrás alapján! "
                     "Ha a forrás alapján nem megválaszolható a kérdés, mondd hogy: "
                     f"{impossible_answer}")
else:
    prompt_prefix = "Válaszold meg az alábbi kérdést a forrás alapján!"

print(f"{prompt_prefix=}")
prompt_col = []
impossible_question_count = 0

with tqdm(total=len(hun_data.index), desc="Processing data") as pbar:
    for index, row in hun_data.loc[:].iterrows():

        if row["answer"] is np.nan:
            hun_data.loc[index, "is_impossible"] = True
        if hun_data.loc[index, "is_impossible"]:
            hun_data.loc[index, "answer"] = impossible_answer
            impossible_question_count = impossible_question_count + 1
        if USE_MOD_ANSWER and (row["modanswer"] is not np.nan):
            hun_data.loc[index, "answer"] = row["modanswer"]

        hun_data.loc[index, "answer"] = hun_data.loc[index, "answer"].strip(r" []'")

        text = (prompt_prefix
                + "\n### Forrás:\n" + str(row['context'])
                + "\n### Kérdés:\n" + str(row['question'])
                + "\n### Válasz:\n" + str(hun_data.loc[index, "answer"]))

        text = text.strip()
        prompt_col.append(text)
        pbar.update(1)
        
hun_data["text"] = prompt_col
print(f"{impossible_question_count=}")


print(f"{len(hun_data)=}")
if not INCLUDE_IMPOSSIBLE:
    hun_data = hun_data[hun_data.answer != impossible_answer]
    print(f"New {len(hun_data)=}")





print(f"{hun_data.shape=}")
hun_data.tail()


hun_data_train, hun_data_temp = train_test_split(hun_data, test_size=0.3, random_state=42)
hun_data_eval, hun_data_test = train_test_split(hun_data_temp, test_size=0.5, random_state=42)


print("hun_data_train shape:", hun_data_train.shape)
print("hun_data_test shape:", hun_data_test.shape)
print("hun_data_eval shape:", hun_data_eval.shape)


hun_data_train_q_c_a_t = hun_data_train[['question', 'context', 'answer', 'text']]
hun_data_test_q_c_a_t = hun_data_test[['question', 'context', 'answer', 'text']]
hun_data_eval_q_c_a_t = hun_data_eval[['question', 'context', 'answer', 'text']]


hun_data_train_q_c_a_t.head()


hun_data_test_q_c_a_t.head()


hun_data_eval_q_c_a_t.head()


hun_data_train_q_c_a_t.to_csv("data/train_w_noansw.csv", index=False, sep=";")
hun_data_test_q_c_a_t.to_csv("data/test_w_noansw.csv", index=False, sep=";")
hun_data_eval_q_c_a_t.to_csv("data/eval_w_noansw.csv", index=False, sep=";")



